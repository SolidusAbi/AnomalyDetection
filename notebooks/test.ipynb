{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "\n",
    "ae_dir = os.path.join(project_dir, 'modules/AutoEncoder')\n",
    "if ae_dir not in sys.path:\n",
    "    sys.path.append(ae_dir)\n",
    "\n",
    "ipdl_dir = os.path.join(project_dir, 'modules/IPDL')\n",
    "if ipdl_dir not in sys.path:\n",
    "    sys.path.append(ipdl_dir)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from autoencoder import SDAE, SDAE_TYPE\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial AutoEncoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 2\n",
    "sdae = SDAE([28*28, 1024, 1024, z_dim], SDAE_TYPE.linear, dropout=False, \n",
    "            activation_func=[nn.ReLU(), nn.ReLU(), nn.Identity()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        r'''\n",
    "            Parameters\n",
    "            ----------\n",
    "                input_dim: int\n",
    "                    Indicate the dimensionality of latent space Z\n",
    "\n",
    "                hidden_dim: int\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.D = nn.Sequential(*[\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(p=.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ])  \n",
    "    def forward(self, x):\n",
    "        return self.D(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "Q = sdae.encode.to(device)\n",
    "\n",
    "# Decoder\n",
    "P = sdae.decode.to(device)\n",
    "\n",
    "# Discriminator\n",
    "D = Discriminator(z_dim, 512).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "dataset_full = MNIST('data/', train = True, download = True, transform = transforms.ToTensor())\n",
    "idx = torch.where((dataset_full.targets == 0) | (dataset_full.targets == 2))[0]\n",
    "\n",
    "x_train_set = Subset(dataset_full, idx)\n",
    "train_loader =  DataLoader(x_train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REMOVE! Just testing!\n",
    "x, y = next(iter(train_loader))\n",
    "plt.imshow(x[0,0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining 2-Dimensional Guassian as prior\n",
    "$p(z) \\sim \\mathcal{N}_n(\\mu, \\sum)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = MultivariateNormal(loc=torch.zeros(2), covariance_matrix=torch.eye(2))\n",
    "\n",
    "plt.imshow(prior.sample((128,)))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning rates\n",
    "gen_lr = 1e-4\n",
    "reg_lr = 5e-5\n",
    "\n",
    "#encode/decode optimizers\n",
    "optim_P = torch.optim.Adam(P.parameters(), lr=gen_lr)\n",
    "optim_Q_enc = torch.optim.Adam(Q.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "optim_Q_gen = torch.optim.Adam(Q.parameters(), lr=reg_lr)\n",
    "optim_D = torch.optim.Adam(D.parameters(), lr=reg_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 120\n",
    "recons_criterion = nn.MSELoss()\n",
    "# recons_criterion = nn.BCELoss()\n",
    "eps = 1e-12\n",
    "tb_writer = SummaryWriter('log/AAE')\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    recons_loss_ = []\n",
    "    disc_loss_ = []\n",
    "    gen_loss_ = []\n",
    "    for idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs.flatten(1)\n",
    "        optim_P.zero_grad()\n",
    "        optim_Q_enc.zero_grad()\n",
    "        optim_Q_gen.zero_grad()\n",
    "        optim_D.zero_grad()\n",
    "\n",
    "        # Reconstruction loss\n",
    "        z = Q(inputs)\n",
    "        out = P(z)\n",
    "\n",
    "        recon_loss = recons_criterion(out, inputs)\n",
    "        recons_loss_.append(recon_loss.item())\n",
    "\n",
    "        recon_loss.backward()\n",
    "        optim_P.step()\n",
    "        optim_Q_enc.step()\n",
    "\n",
    "        # Discriminator\n",
    "        # Prior as an multivariate gaussian function $p(z) \\sim \\mathcal{N}_n(\\mu, \\sum)$\n",
    "        # this is constraining the Z-projection to be normal!\n",
    "        Q.eval()\n",
    "        z_real_gauss = prior.sample((inputs.size(0),)).to(device)\n",
    "        D_real_gauss = D(z_real_gauss)\n",
    "\n",
    "        z_fake_gauss = Q(inputs)\n",
    "        D_fake_gauss = D(z_fake_gauss)\n",
    "\n",
    "        D_loss = -torch.mean(torch.log(D_real_gauss + eps) + torch.log(1 - D_fake_gauss + eps))\n",
    "        disc_loss_.append(D_loss.item())\n",
    "\n",
    "        D_loss.backward()\n",
    "        optim_D.step()\n",
    "\n",
    "        # Generator\n",
    "        Q.train()\n",
    "        z_fake_gauss = Q(inputs)\n",
    "        D_fake_gauss = D(z_fake_gauss)\n",
    "        \n",
    "        G_loss = -torch.mean(torch.log(D_fake_gauss + eps))\n",
    "        gen_loss_.append(G_loss.item())\n",
    "\n",
    "        G_loss.backward()\n",
    "        optim_Q_gen.step()\n",
    "\n",
    "    tb_writer.add_scalar('test/reconstruction', np.array(recons_loss_).mean(), epoch)\n",
    "    tb_writer.add_scalar('test/Discrimator', np.array(disc_loss_).mean(), epoch)\n",
    "    tb_writer.add_scalar('test/Generator', np.array(gen_loss_).mean(), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Q(inputs)\n",
    "out = P(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(inputs)-1)\n",
    "test_in = inputs[idx].reshape(28,28)\n",
    "test_out = out[idx].reshape(28,28)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_out.cpu().detach())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_in.cpu().detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d9b8aa8d774518be7ebcfd06a2463a8035a66798fac49b1a363f570d2d8622e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
