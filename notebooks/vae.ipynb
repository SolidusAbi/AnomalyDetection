{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "\n",
    "sparse_dir = os.path.join(project_dir, 'modules/Sparse')\n",
    "if sparse_dir not in sys.path:\n",
    "    sys.path.append(sparse_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "dataset_full = MNIST('data/', train = True, download = True, transform = transforms.ToTensor())\n",
    "# idx = torch.where((dataset_full.targets == 0) | (dataset_full.targets == 2))[0]\n",
    "normal_idx = torch.where((dataset_full.targets == 4))[0]\n",
    "anomaly_idx = torch.where((dataset_full.targets == 9))[0]\n",
    "idx = torch.cat([normal_idx, anomaly_idx[:512]])\n",
    "\n",
    "x_train_set = Subset(dataset_full, idx)\n",
    "train_loader =  DataLoader(x_train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO REMOVE! Just testing!\n",
    "x, y = next(iter(train_loader))\n",
    "plt.imshow(x[0,0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3591)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor(1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.3026), tensor(0.1000))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(0.1)), torch.exp(torch.tensor(-2.3026))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sparse.modules.variational import VariationalLayer\n",
    "from Sparse.modules.variational.utils import SGVBL\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "class VariationalEncoder(nn.Linear, nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True) -> None:\n",
    "        super(VariationalEncoder, self).__init__(in_features, out_features, bias)\n",
    "        self.log_sigma_weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "\n",
    "        self.mu, self.sigma = None, None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        mu = F.linear(x, self.weight, self.bias)\n",
    "        sigma = torch.exp(F.linear(x, self.log_sigma_weight))\n",
    "\n",
    "        if self.training:\n",
    "            self.mu, self.sigma = mu, sigma\n",
    "\n",
    "        # Reparameterization trick\n",
    "        eps = torch.normal(0, torch.ones_like(sigma))\n",
    "        return mu + sigma * eps\n",
    "\n",
    "    def kl_reg(self):\n",
    "        # KL-Divergence regularization\n",
    "        return .5 * (self.mu**2 + self.sigma**2 - torch.log(self.sigma**2) - 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.distributions.Normal(0, 1)\n",
    "N.loc = N.loc.cuda() # hack to get sampling on the GPU\n",
    "N.scale = N.scale.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: 0.0, scale: 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def Encode(nn.Module):\n",
    "    def __init__(self, input_size, latent_space):\n",
    "        super(Encode, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,8, 3, stride=1, padding=1),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(8, 16, 3, stride=1, padding=1),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(16, 24, 3, stride=1, padding=1),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "def Botleneck(nn.Module):\n",
    "    def __init__(self, input_size, latent_space):\n",
    "        super(Botleneck, self).__init__()\n",
    "        self.z = nn.Sequential(\n",
    "            nn.Linear(input_size, latent_space),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_space, input_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "# z_size = input_size // (2*3)\n",
    "# self.z = nn.Sequential(z_size, latent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 4, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "test = nn.Sequential(\n",
    "        nn.Conv2d(1,8, 3, stride=1, padding=1),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(3, stride=2, padding=1),\n",
    "        nn.Conv2d(8, 16, 3, stride=1, padding=1),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(3, stride=2, padding=1),\n",
    "        nn.Conv2d(16, 24, 3, stride=1, padding=1),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(3, stride=2, padding=1),\n",
    "    )\n",
    "\n",
    "x = torch.randn(1,1,28,28)\n",
    "test(x).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28//(2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(28 + 2*1 - 3)/1 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1568, 1024, 384, 256, 128)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*14*14, 16*8*8, 24*4*4, 64*2*2, 128*1*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
